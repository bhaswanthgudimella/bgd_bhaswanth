[2024-04-05 13:00:42 Info] Script args: Namespace(dataset='ds_padded_cont_permuted_mnist', nn_arch='mnist_simple_net_200width_domainlearning_1024input_10cls_1ds', logname='continuous_permuted_mnist_10tasks', results_dir='res', seed=2019, num_workers=1, num_epochs=15, batch_size=64, pruning_percents=[], train_mc_iters=10, std_init=0.06, mean_eta=1, permanent_prune_on_epoch=-1, permanent_prune_on_epoch_percent=90, test_freq=10, contpermuted_beta=4, optimizer='bgd', optimizer_params='{}', inference_mc=True, inference_map=True, inference_committee=True, inference_aggsoftmax=True, inference_initstd=True, committee_size=10, test_mc_iters=10, init_params=['{"bias_type":', '"xavier",', '"conv_type":', '"xavier",', '"bn_init":', '"01"}'], desc=['BGD', 'on', 'continuous', 'permuted', 'mnist'], bw_to_rgb=False, permuted_offset=False, labels_trick=False, num_of_permutations=2, iterations_per_virtual_epc=938, separate_labels_space=False, permute_seed=2019)
[2024-04-05 13:00:42 Info] Computer name: iiitd with pytorch version: 2.2.2
[2024-04-05 13:00:42 Info] Transformed model to CUDA
[2024-04-05 13:00:42 Info] Initialized 0 Conv2d layers using nn.init.xavier_normal_
[2024-04-05 13:00:42 Info] Initialized 3 linear layers using xavier
[2024-04-05 13:00:42 Info] Initialized 0 bias conv2d layers using nn.init.xavier.noraml_
[2024-04-05 13:00:42 Info] Initialized 3 bias linear layers using xavier
[2024-04-05 13:00:42 Info] Initialized 0 BN layers using weight=1 and bias=0
[2024-04-05 13:00:42 Info] BGD params: {'mean_eta': 1, 'std_init': 0.06, 'mc_iters': 10}
[2024-04-05 13:00:42 Info] Inference method: {'map', 'init_std', 'committee', 'agg_softmax', 'test_mc'}
[2024-04-05 13:00:42 Info] Number of parameters in the model is 247,210
[2024-04-05 13:00:42 Info] Criterion parameters: type=<class 'torch.nn.modules.loss.CrossEntropyLoss'>
[2024-04-05 13:00:42 Info] Running training from epoch 1 to epoch 15
[2024-04-05 13:00:42 Info] Training epoch number 1 with dataset number 0
[2024-04-05 13:00:45 Info] Epoch 1, train set, Iter 100 current average loss 1.0007363820523008 current average acc 0.0%
[2024-04-05 13:00:47 Info] Epoch 1, train set, Iter 200 current average loss 0.7048330916203566 current average acc 0.0%
[2024-04-05 13:00:48 Info] Epoch 1, train set, Iter 300 current average loss 0.5797222898751495 current average acc 0.0%
[2024-04-05 13:00:50 Info] Epoch 1, train set, Iter 400 current average loss 0.5002934888256725 current average acc 0.0%
[2024-04-05 13:00:51 Info] Epoch 1, train set, Iter 500 current average loss 0.44965224900990824 current average acc 0.0%
[2024-04-05 13:00:52 Info] Epoch 1, train set, Iter 600 current average loss 0.4109567244127397 current average acc 0.0%
[2024-04-05 13:00:54 Info] Epoch 1, train set, Iter 700 current average loss 0.38264512789941274 current average acc 0.0%
[2024-04-05 13:00:55 Info] Epoch 1, train set, Iter 800 current average loss 0.35936660168133727 current average acc 0.0%
[2024-04-05 13:00:57 Info] Epoch 1, train set, Iter 900 current average loss 0.341528598412666 current average acc 0.0%
[2024-04-05 13:00:57 Info] Stats for train set of size 60032, loss is 0.3351179114666035, acc is 0.0%
[2024-04-05 13:00:57 Info] Running test set for epoch number 1 for dataset idx 0 using map
